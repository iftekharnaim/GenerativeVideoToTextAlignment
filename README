Run HMM1 model (monotonic)
==========================

On Anvil data:
> python hmm_multivideos.py False True

On Vision data:
> python hmm_multivideos.py False False


Run HMM2 (non-monotonic)
========================

On Anvil data:
> python hmm_multivideos.py True True

On Vision data:
> python hmm_multivideos.py True False


Run LHMM1 (monotonic, unobserved)
================================

On Anvil data:
> python latent_hmm_multivideos.py False True

On Vision data:
> python latent_hmm_multivideos.py False False

Run LHMM2 (non-monotonic, unobserved)
================================

On Anvil data:
> python latent_hmm_multivideos.py True True

On Vision data:
> python latent_hmm_multivideos.py True False



Dataset Description:
====================

There are 3 directories: protocols, video_blobs, and vision_3d_coord.

Directory “protocols” - contains the raw text and parses for 3 wetlab protocols: CELL, LLGM, and YPAD.

Directory “video_blobs” - contains the annotations of the set of blobs touched by hands in the videos. The files that contains “vision” in their name are generated by automated tracking. The files that do not have “vision” in their name (and upper case) are the manual tracking data via Anvil.

Directory “vision_3d_coord” - X, Y, Z coordinates for the tracked objects.

